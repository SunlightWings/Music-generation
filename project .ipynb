{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display \n",
    "import keras \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "from mido import MidiFile\n",
    "import pretty_midi \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stats\n",
    "import scipy\n",
    "import psola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\Users\\prabin\\OneDrive\\Desktop\\minor project\\chopin.wav'\n",
    "y = librosa.load(path, sr = None )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid = MidiFile('.\\.\\minor project\\Chopin.midi', clip=True)\n",
    "print(mid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of instruments:', len( pretty_midi.PrettyMIDI(\".\\.\\minor project\\Chopin.midi\").instruments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, sampling_frequency = librosa.load('.\\.\\minor project\\Chopin.midi')\n",
    "T = 1 / sampling_frequency\n",
    "N = len(data)\n",
    "t = N / sampling_frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = sm.tsa.acf(data, nlags =2000)\n",
    "peaks = find_peaks(auto) [0]\n",
    "lags = peaks[0]\n",
    "pitch = sampling_frequency / lag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo, voiced_flag, voiced_probabilities = librosa.pyin(audio, framelength = 20, hoplength = 80, sr = 2222, fmin = 20, fmax = 20000 )\n",
    "pitch__shifted_signal = psola.vocode(audio, sample_rate = int (sr), target_pitch = corrected_fo, fmin =20, fmax =20000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma = librosa.feature.chroma_-stft(y)\n",
    "fig, ax = plt.subplots()\n",
    "img = librosa.display.specshow(chroma, y_axis = 'chroma', x_axis = 'time',ax = ax)\n",
    "ax.set(title = 'chromogram')\n",
    "fig.colorbar(img, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempo, beats = librosa.beat.beat_track (y = data, sr = 2222)\n",
    "length = librosa.get_duration (y = data, sr =2222)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separates music into harmonic and percussive elements\n",
    "y_harmonic, y percussive = librosa.efects.hpss(data)\n",
    "\n",
    "librosa.display.waveshow(y_harmonic, sr = 2222, ax = ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for categorization of modes we calculate the interval difference between notes\n",
    "ionian = [       ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "928db57fa97364b9b019f963370c1fdf7d3044b94bbfb1c70c9a3a5d485d1578"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
